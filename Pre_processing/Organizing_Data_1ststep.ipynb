{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Organizing Data (1st step).ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1T-jd4Wd5cS8R-gr8_9wayy54r0Eqi7Hx","authorship_tag":"ABX9TyNSdOlsyO9+pVjimCp2+/FU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"2Kxa_AESy-xO"}},{"cell_type":"code","source":["# https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\n","!pip install kaggle\n","! mkdir ~/.kaggle\n","\n","! kaggle datasets download clmentbisaillon/fake-and-real-news-dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kb46L5VxazKw","executionInfo":{"status":"ok","timestamp":1641372784049,"user_tz":-210,"elapsed":5130,"user":{"displayName":"zahra ghadiri","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12753995234969589722"}},"outputId":"7a17df16-d31e-43dd-e005-1fcf14cd29cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n","    self.config_file, self.config_dir))\n","IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"]}]},{"cell_type":"code","metadata":{"id":"782ahACbSdYD"},"source":["import json\n","import numpy as np\n","import re\n","import random\n","import pandas as pd\n","\n","import datetime\n","from datetime import timedelta\n","from datetime import datetime\n","\n","from bs4 import BeautifulSoup\n","\n","from nltk.tokenize import WordPunctTokenizer\n","tok = WordPunctTokenizer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eKveYFMvS_b-"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"8UrrKJiparIE"},"source":["def pre_process(text):\n","  text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n","  text = ' '.join(x for x in text.split() if x.startswith('http') == False and x.startswith('www') == False)\n","  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","  text = re.sub(r'^www?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n","  # extra step to make sure html tags are completely removed\n","  clean = re.compile('<.*>|<.*\\\"')\n","  text = re.sub(clean, '', text)\n","  text = re.sub(\"(pic.*)\",\"\", text)\n","  text = re.sub(r\"http\\S+\",\"\", text)\n","  text = re.sub(r\"nyti\\S+\",\"\", text)\n","  text = re.sub(r\"lat\\S+\",\"\", text)\n","  text = re.sub(r\"bos\\S+\",\"\", text)\n","  text = re.sub(r\"wapo\\S+\",\"\", text)\n","  text = re.sub(\"(twitter.*)\",\"\", text)\n","  text=re.sub(\"<!--?.*?-->\",\"\",text)\n","  text = re.sub(\"(dlvr.*)\",\"\", text)\n","  text=text.replace(u'\\u200c',\" \")\n","\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"voa5bs4WE-Cv"},"source":["def encoding_fixer(text):\n","\n","    pat1 = r'@[A-Za-z0-9]+'\n","    pat2 = r'https?://[A-Za-z0-9./]+'\n","    combined_pat = r'|'.join((pat1, pat2))\n","\n","    soup = BeautifulSoup(text, 'lxml')\n","    souped = soup.get_text()\n","    stripped = re.sub(combined_pat, '', souped)\n","    try:\n","        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n","    except:\n","        clean = stripped\n","    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n","    lower_case = letters_only.lower()\n","    # During the letters_only process two lines above, it has created unnecessay white spaces,\n","    # I will tokenize and join together to remove unneccessary white spaces\n","    words = tok.tokenize(lower_case)\n","    return (\" \".join(words)).strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLel8j6bnXbm"},"source":["def fix_time_format(t):\n","  try:\n","    return datetime.strptime(t.strip(' \\t\\r\\n'), \"%B %d, %Y\")\n","  except:\n","    try:\n","      return datetime.strptime(t.strip(' \\t\\r\\n'), \"%b %d, %Y\")\n","    except:\n","      try:\n","        return datetime.strptime(t.strip(' \\t\\r\\n'), \"%d-%b-%y\")\n","      except:\n","        print(\"error\")"],"execution_count":null,"outputs":[]}]}