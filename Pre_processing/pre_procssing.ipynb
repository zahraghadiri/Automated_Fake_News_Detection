{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tok = WordPunctTokenizer()\n",
    "# Functions\n",
    "def pre_process(text):\n",
    "  text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
    "  text = ' '.join(x for x in text.split() if x.startswith('http') == False and x.startswith('www') == False)\n",
    "  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  text = re.sub(r'^www?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "  # extra step to make sure html tags are completely removed\n",
    "  clean = re.compile('<.*>|<.*\\\"')\n",
    "  text = re.sub(clean, '', text)\n",
    "  text = re.sub(\"(pic.*)\",\"\", text)\n",
    "  text = re.sub(r\"http\\S+\",\"\", text)\n",
    "  text = re.sub(r\"nyti\\S+\",\"\", text)\n",
    "  text = re.sub(r\"lat\\S+\",\"\", text)\n",
    "  text = re.sub(r\"bos\\S+\",\"\", text)\n",
    "  text = re.sub(r\"wapo\\S+\",\"\", text)\n",
    "  text = re.sub(\"(twitter.*)\",\"\", text)\n",
    "  text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "  text = re.sub(\"(dlvr.*)\",\"\", text)\n",
    "  text=text.replace(u'\\u200c',\" \")\n",
    "\n",
    "  return text\n",
    "def encoding_fixer(text):\n",
    "\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n",
    "def fix_time_format(t):\n",
    "  try:\n",
    "    return datetime.strptime(t.strip(' \\t\\r\\n'), \"%B %d, %Y\")\n",
    "  except:\n",
    "    try:\n",
    "      return datetime.strptime(t.strip(' \\t\\r\\n'), \"%b %d, %Y\")\n",
    "    except:\n",
    "      try:\n",
    "        return datetime.strptime(t.strip(' \\t\\r\\n'), \"%d-%b-%y\")\n",
    "      except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_ner(document):\n",
    "  return {(ent.text.strip(), ent.label_) for ent in nlp(document).ents}\n",
    "\n",
    "def NER(dataset):\n",
    "  ne_list=[]\n",
    "  for i in range(dataset.shape[0]):\n",
    "\n",
    "    spcy_ner=spacy_ner(dataset.title[i])\n",
    "    ne=[]\n",
    "    for j in spcy_ner:\n",
    "      \n",
    "      ne.append(j[0])\n",
    "    ne_list.append(ne)\n",
    "\n",
    "  dataset[\"NE\"]=ne_list\n",
    "  return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0f335aa8fb138d8743014ad643811be914af67353f395387f07e8fe251a1bf6e"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.7.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}